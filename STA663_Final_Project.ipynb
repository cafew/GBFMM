{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline of Algorithm: \n",
    "\n",
    "The paper I have chosen describes a type of finite mixture algorithm, one for modeling patterns of an outcome of interest as clusters across time. The method is termed by the authors as Group-based Latent Trajectory Modeling, and was developed by Daniel Nagin in 1999.\n",
    "\n",
    "The general specification for the group based latent trajectory models is provided in equations (1) and (2). Equation (1) describes the basic form of the finite mixture model--i.e., summing a finite number of latent groupings believed to compose the underlying population. Since group membership is not observed, the proportion of the $j$ underlying population belonging to each of the latent trajectory groups $\\pi_j$, must be estimated. This requires the aggregation of the $J$ conditional likelihood functions, forming the unconditional probability of the data, $Y_i$ (Nagin 2005).\n",
    "\n",
    "\n",
    "$$P(Y_i) = \\sum_{j}^J \\pi_j P^j (Y_i)\\tag{1}$$ \n",
    "\n",
    "Here, $P(Y_i)$ estimates the unconditional probability of seeing the trajectory of the outcome measure for individual $i$. \n",
    "\n",
    "The key to the \"group-based\" approach is an underlying idea called \"conditional independence.\" The likelihood function this produces is denoted in equation (2). For a give group $j$, conditional independence makes the assumption that the distribution of $y_{it}$ is independent of the observed value of the outcome in prior periods, $y_{it-1}$,  $y_{it-2}$,... This assumption helps to reduce the complexity of the model, and when combined with the EM algorithm, allows for identification of latent trajectory groupingsdespite the complex nature of the model and data.\n",
    "\n",
    "$$L = \\prod^N P(Y_i)\\tag{2}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readme for Python Module: \n",
    "\n",
    "### Group-Based Finite Mixture Models: A Latent Trajectory Approach \n",
    "\n",
    "**Code for course project use only at this time.**\n",
    "\n",
    "Final project for STA 663 \n",
    "* Takes time variable and continuous outcome \n",
    "* Generates latent trajectories (time-dependent clusters) of outcome behavior over time \n",
    "\n",
    "**Dependencies**\n",
    "\n",
    "Required\n",
    "\n",
    "* Python (created using 2.7.x)\n",
    "* Numpy\n",
    "* Scipy \n",
    "* Pymix (https://github.com/klahnakoski/pymix.git)\n",
    "\n",
    "**Recommended**\n",
    "\n",
    "* ggplot (for trajectory plotting function included in the repository)\n",
    "* pandas (for trajectory plotting function included in the repository)\n",
    "* STAN (for Bayesian alternative specification)\n",
    "* pystan (for Bayesian alternative specification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from mixture import *\n",
    "import mixture\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ggplot import *\n",
    "import pandas as pd\n",
    "\n",
    "# ------- #\n",
    "# Normal Mixture #\n",
    "# ------- #\n",
    "# Normal Distribution Functions \n",
    "\n",
    "# Generate Means of Normal Mixture\n",
    "def norm_means(data): \n",
    "    cols = data.shape[1]\n",
    "    return np.repeat(0.0,cols) \n",
    "\n",
    "# Generate Covariance Structure of Normal Mixture\n",
    "def norm_cov(data):\n",
    "    m = data.shape[1]\n",
    "    covs = np.repeat(1.0,m) \n",
    "    return np.diag(covs)\n",
    "\n",
    "# Single Multivariate Normal distribution function\n",
    "def norm_singdist(ng, data):\n",
    "    m = data.shape[1]\n",
    "    dist = mixture.MultiNormalDistribution(m, \n",
    "        norm_means(data),norm_cov(data))\n",
    "    return dist\n",
    "\n",
    "# Generalize to multiple clusters of multivariate distribution function\n",
    "def norm_multdist(ng, data):\n",
    "    temp = list()\n",
    "    for x in range(ng):\n",
    "        temp.append(norm_singdist(2, TO1adj))\n",
    "    return temp\n",
    "\n",
    "# Data functions\n",
    "def build_mix_dat(data):\n",
    "    mixdat = mixture.DataSet()\n",
    "    mixdat.fromArray(data)\n",
    "    return mixdat\n",
    "\n",
    "# Normal Mixture Model \n",
    "def intialize_normal_model(ng, data):\n",
    "    mod_ps = np.repeat(1.0/ng, ng)\n",
    "    if ng ==2:\n",
    "        n1,n2 = norm_multdist(ng, data)\n",
    "        mix_ = mixture.MixtureModel(ng, mod_ps,[n1,n2])\n",
    "    elif ng == 3:  \n",
    "        n1,n2,n3 = norm_multdist(ng, data)\n",
    "        mix_ = mixture.MixtureModel(ng, mod_ps,[n1,n2,n3])\n",
    "    elif ng == 4:  \n",
    "        n1,n2,n3,n4 = norm_multdist(ng, data)\n",
    "        mix_ = mixture.MixtureModel(ng, mod_ps,[n1,n2,n3,n4])\n",
    "    elif ng == 5:  \n",
    "        n1,n2,n3,n4,n5 = norm_multdist(ng, data)\n",
    "        mix_ = mixture.MixtureModel(ng, mod_ps,[n1,n2,n3,n4,n5])\n",
    "    elif ng == 6:  \n",
    "        n1,n2,n3,n4,n5,n6 = norm_multdist(ng, data)\n",
    "        mix_ = mixture.MixtureModel(ng, mod_ps,[n1,n2,n3,n4,n5,n6])\n",
    "    elif ng == 7:  \n",
    "        n1,n2,n3,n4,n5,n6,n7 = norm_multdist(ng, data)\n",
    "        mix_ = mixture.MixtureModel(ng, mod_ps,[n1,n2,n3,n4,n5,n6,n7])\n",
    "    elif ng == 8:  \n",
    "        n1,n2,n3,n4,n5,n6,n7,n8 = norm_multdist(ng, data)\n",
    "        mix_ = mixture.MixtureModel(ng, mod_ps,[n1,n2,n3,n4,n5,n6,n7,n8])\n",
    "    return mix_ \n",
    "\n",
    "# Run Normal Mixture Model\n",
    "def normal_mixmod(ng, data):\n",
    "    mix_mod = intialize_normal_model(ng, data)\n",
    "    mix_dat = build_mix_dat(data)\n",
    "    mix_mod.modelInitialization(mix_dat)\n",
    "    mix_mod.EM(mix_dat, 40,.2)\n",
    "    mix_mod.classify(mix_dat)\n",
    "    return mix_mod\n",
    "   \n",
    "# Results \n",
    "def GBFMM(ng,data): \n",
    "    out = normal_mixmod(ng, data)\n",
    "    traj = list()\n",
    "    for i in range(ng):\n",
    "        traj.append(out.components[i].distList[0].mu)\n",
    "    return traj\n",
    "\n",
    "# Trajectory Plotting Function\n",
    "def plot_traj(outs):\n",
    "    if len(outs) == 2:\n",
    "        d = {'one' : outs[0], \n",
    "        'two' : outs[1], \n",
    "        'Time': range(1,len(outs[0])+1)}\n",
    "    elif len(outs) == 3:\n",
    "        d = {'one' : outs[0], \n",
    "        'two' : outs[1], \n",
    "        'three' : outs[2], \n",
    "        'Time': range(1,len(outs[0])+1)}\n",
    "    elif len(outs) == 4: \n",
    "        d = {'one' : outs[0], \n",
    "        'two' : outs[1], \n",
    "        'three' : outs[2], \n",
    "        'four' : outs[3], \n",
    "        'Time': range(1,len(outs[0])+1)}\n",
    "    elif len(outs) == 5:\n",
    "        d = {'one' : outs[0], \n",
    "        'two' : outs[1], \n",
    "        'three' : outs[2], \n",
    "        'four' : outs[3], \n",
    "        'five' : outs[4], \n",
    "        'Time': range(1,len(outs[0])+1)}\n",
    "    elif len(outs) == 6:\n",
    "        d = {'one' : outs[0], \n",
    "        'two' : outs[1], \n",
    "        'three' : outs[2], \n",
    "        'four' : outs[3], \n",
    "        'five' : outs[4], \n",
    "        'six' : outs[5], \n",
    "        'Time': range(1,len(outs[0])+1)}\n",
    "    elif len(outs) == 7: \n",
    "        d = {'one' : outs[0],\n",
    "        'two' : outs[1], \n",
    "        'three' : outs[2], \n",
    "        'four' : outs[3], \n",
    "        'five' : outs[4], \n",
    "        'six' : outs[5], \n",
    "        'seven' : outs[6], \n",
    "        'Time': range(1,len(outs[0])+1)}\n",
    "    elif len(outs) == 8:\n",
    "        d = {'one' : outs[0],\n",
    "        'two' : outs[1], \n",
    "        'three' : outs[2], \n",
    "        'four' : outs[3], \n",
    "        'five' : outs[4], \n",
    "        'six' : outs[5], \n",
    "        'seven' : outs[6], \n",
    "        'eight' : outs[7], \n",
    "        'Time': range(1,len(outs[0])+1)}\n",
    "    dat = pd.DataFrame(d) \n",
    "    dm = pd.melt(dat, id_vars=['Time'], var_name='Latent Class', value_name='Value') \n",
    "    print ggplot(dm, aes('Time', 'Value', color='Latent Class')) + \\\n",
    "        geom_point(size=80) + \\\n",
    "        geom_line(size=3) + \\\n",
    "        theme_bw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Application and comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
